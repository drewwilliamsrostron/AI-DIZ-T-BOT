def test_end_to_end_smoke():
        sys.modules["openai"] = types.SimpleNamespace()
        data = load_csv_hourly("Gemini_BTCUSD_1h.csv")[:1500]
        assert len(data) > 24
        ensemble = EnsembleModel(
            device=torch.device("cpu"), n_models=1, lr=1e-4, weight_decay=1e-4
        )
        stop_event = threading.Event()
        csv_training_thread(
            ensemble,
            data,
            stop_event,
            {"ADAPT_TO_LIVE": False},
            use_prev_weights=False,
            max_epochs=1,
        )
        result = robust_backtest(ensemble, data)
        assert result["trades"] > 0
>       assert g.epoch_count == 1
E       assert 0 == 1
E        +  where 0 = g.epoch_count

tests\test_smoke.py:32: AssertionError
--------------------------------- Captured Err ---------------------------------
Traceback (most recent call last):
  File "C:\Users\dwrostron\Documents\GitHub\AI-t-bot\artibot\training.py", line 84, in csv_training_thread
    tl, vl = ensemble.train_one_epoch(dl_train, dl_val, train_data, stop_event)
             ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dwrostron\Documents\GitHub\AI-t-bot\artibot\ensemble.py", line 163, in train_one_epoch
    for batch_idx, (batch_x, batch_y) in enumerate(dl_train):
                                         ~~~~~~~~~^^^^^^^^^^
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\utils\data\dataloader.py", line 493, in __iter__
    return self._get_iterator()
           ~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\utils\data\dataloader.py", line 424, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\site-packages\torch\utils\data\dataloader.py", line 1171, in __init__
    w.start()
    ~~~~~~~^^
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ~~~~~~~~~~~^^^^^^
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\popen_spawn_win32.py", line 97, in __init__
    reduction.dump(process_obj, to_child)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^
_pickle.PicklingError: Can't pickle <class 'artibot.dataset.HourlyDataset'>: it's not the same object as artibot.dataset.HourlyDataset
Traceback (most recent call last):

  File "<string>", line 1, in <module>

    from multiprocessing.spawn import spawn_main; spawn_main(parent_pid=21036, pipe_handle=1068)

                                                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\spawn.py", line 113, in spawn_main

    new_handle = reduction.duplicate(pipe_handle,

                                     source_process=source_process)

  File "C:\Users\dwrostron\AppData\Local\Programs\Python\Python313\Lib\multiprocessing\reduction.py", line 79, in duplicate

    return _winapi.DuplicateHandle(

           ~~~~~~~~~~~~~~~~~~~~~~~^

        source_process, handle, target_process,

        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

        0, inheritable, _winapi.DUPLICATE_SAME_ACCESS)

        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

OSError: [WinError 6] The handle is invalid



